{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cb880384-f5cf-46d2-9a9c-61068b93f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd2c631a-002a-4a61-8ad8-e9c5aa902bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\vkush\\\\OneDrive\\\\Desktop\\\\research equity tool\\\\nvda_news_1.txt'}, page_content=\"The stock of NVIDIA Corp (NASDAQ:NVDA) experienced a daily loss of -3.56% and a 3-month gain of 32.35%. With an Earnings Per Share (EPS) (EPS) of $1.92, the question arises: is the stock significantly overvalued? This article aims to provide a detailed valuation analysis of NVIDIA, offering insights into its financial strength, profitability, growth, and more. We invite you to delve into this comprehensive analysis.\\n\\nCompany Overview\\nWarning! GuruFocus has detected 10 Warning Signs with NVDA. Click here to check it out.\\n\\nNVDA 30-Year Financial Data\\n\\nThe intrinsic value of NVDA\\n\\n\\nNVIDIA Corp (NASDAQ:NVDA) is a leading designer of discrete graphics processing units that enhance the experience on computing platforms. The firm's chips are widely used in various end markets, including PC gaming and data centers. In recent years, NVIDIA has broadened its focus from traditional PC graphics applications such as gaming to more complex and favorable opportunities, including artificial intelligence and autonomous driving, leveraging the high-performance capabilities of its products.\\n\\nCurrently, NVIDIA's stock price stands at $418.01, significantly higher than the GF Value of $310.28, indicating the stock might be overvalued. With a market cap of $1 trillion, the valuation seems steep. The following analysis aims to delve deeper into the company's value.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nUnderstanding the GF Value\\nThe GF Value is a unique measure of the intrinsic value of a stock, calculated based on historical trading multiples, a GuruFocus adjustment factor, and future business performance estimates. If the stock price is significantly above the GF Value Line, it is overvalued, and its future return is likely to be poor. Conversely, if it is significantly below the GF Value Line, its future return will likely be higher.\\n\\nAccording to GuruFocus Value calculation, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. The stock's current price of $418.01 per share and the market cap of $1 trillion further strengthen this assumption.\\n\\nGiven that NVIDIA is significantly overvalued, the long-term return of its stock is likely to be much lower than its future business growth.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nLink: These companies may deliver higher future returns at reduced risk.\\n\\nFinancial Strength of NVIDIA\\nExamining the financial strength of a company is crucial before investing in its stock. Companies with poor financial strength pose a higher risk of permanent loss. NVIDIA's cash-to-debt ratio of 1.27 is worse than 58.04% of companies in the Semiconductors industry. However, NVIDIA's overall financial strength is 8 out of 10, indicating a strong financial position.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nProfitability and Growth\\nConsistent profitability over the long term reduces the risk for investors. NVIDIA, with its profitability ranking of 10 out of 10, has been profitable for the past 10 years. The company's operating margin of 17.37% ranks better than 76.5% of companies in the Semiconductors industry.\\n\\nHowever, growth is a crucial factor in a company's valuation. NVIDIA's growth ranks worse than 52.99% of companies in the Semiconductors industry, with its 3-year average revenue growth rate better than 87.88% of companies in the industry.\\n\\nROIC vs WACC\\nComparing a company's return on invested capital (ROIC) to its weighted average cost of capital (WACC) is an effective way to evaluate its profitability. Over the past 12 months, NVIDIA's ROIC was 20.32 while its WACC was 16.74, suggesting that the company is creating value for its shareholders.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nConclusion\\nIn conclusion, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. Despite its strong financial condition and profitability, its growth ranks lower than 52.99% of companies in the Semiconductors industry. To learn more about NVIDIA stock, you can check out its 30-Year Financials here.\\n\\nTo find out the high quality companies that may deliver above-average returns, please check out GuruFocus High Quality Low Capex Screener.\\n\\nThis article first appeared on GuruFocus.\")]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"C:\\\\Users\\\\vkush\\\\OneDrive\\\\Desktop\\\\research equity tool\\\\nvda_news_1.txt\")\n",
    "data=loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f9ef5dab-068f-4792-9943-f2fa6e82fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5214df86-9cda-498b-9e94-f0c6c3ab7ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(\"C:\\\\Users\\\\vkush\\\\OneDrive\\\\Desktop\\\\research equity tool\\\\movies.csv\", source_column=\"title\")\n",
    "data=loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c43a1760-7182-444f-9af4-2d02e6fed50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Doctor Strange in the Multiverse of Madness', 'row': 1}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97cb82-cfc9-441e-9c06-101d7b05ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install unstructured libmagic python-magic python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19da246d-1cce-4ee4-9476-bf9d0af7edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "67cf0573-a042-4540-ab31-506d4e152feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader= UnstructuredURLLoader(urls=[\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-mahindra-gain-certificates-for-production-linked-payouts-11281691.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9124ad0a-d60a-496c-a9e9-957205ab0aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f34825a4-3b4e-482d-a942-cf54f70d2e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.moneycontrol.com/news/business/tata-motors-mahindra-gain-certificates-for-production-linked-payouts-11281691.html'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "09f2edf3-a4bf-4dfd-ab01-e882134d145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = \"\"\"Interstellar is a 2014 epic science fiction drama film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan. It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, and Michael Caine. Set in a dystopian future where Earth is suffering from catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "\n",
    "The screenplay had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg. Theoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar. It was Lynda Obst's final film as producer before her death. Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Filming began in late 2013 and took place in Alberta, Klaustur, and Los Angeles. Interstellar uses extensive practical and miniature effects, and the company DNEG created additional digital effects.\n",
    "\n",
    "Interstellar was released in theaters on November 7, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally positive reviews and grossed $681 million worldwide during its initial theatrical run, making it the tenth-highest-grossing film of 2014. Among its various accolades, Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d7b924f5-8a03-451a-9d88-5c2c8ed3e56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interstellar is a 2014 epic science fiction drama film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan. It stars Matthew McConaughey, Anne Hathaway, Jessica Chasta'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7aee5323-0b61-47e9-8453-a8055bea8354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 205, which is longer than the specified 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter=CharacterTextSplitter(\n",
    "    separator=\".\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0\n",
    ")  \n",
    "chunks = splitter.split_text(text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "318429f3-0fad-45a6-9659-eb1eb4c95025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "107\n",
      "204\n",
      "127\n",
      "151\n",
      "173\n",
      "197\n",
      "162\n",
      "164\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e0605a9e-b977-4f66-8654-b8c55d1ad033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interstellar is a 2014 epic science fiction drama film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan',\n",
       " 'It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, and Michael Caine',\n",
       " 'Set in a dystopian future where Earth is suffering from catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind',\n",
       " 'The screenplay had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg',\n",
       " 'Theoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar',\n",
       " \"It was Lynda Obst's final film as producer before her death. Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm\",\n",
       " 'Filming began in late 2013 and took place in Alberta, Klaustur, and Los Angeles. Interstellar uses extensive practical and miniature effects, and the company DNEG created additional digital effects',\n",
       " 'Interstellar was released in theaters on November 7, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors',\n",
       " 'The film received generally positive reviews and grossed $681 million worldwide during its initial theatrical run, making it the tenth-highest-grossing film of 2014',\n",
       " 'Among its various accolades, Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64473144-d2a5-4b63-a64a-e2a08f24bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0e64662e-cb4d-4682-aa1d-b685f654bd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter=RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\",\" \"],\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "chunks=r_splitter.split_text(text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "67fecb94-d55d-4b27-9808-cd766e066332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193\n",
      "193\n",
      "67\n",
      "191\n",
      "198\n",
      "198\n",
      "65\n",
      "191\n",
      "197\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print (len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5fed776d-86e6-43aa-a9de-51abef5c72fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n",
      "655\n",
      "458\n"
     ]
    }
   ],
   "source": [
    "chunks=text.split(\"\\n\\n\")\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7d92cf4-9c46-49f9-b5ca-24ff10423925",
   "metadata": {},
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9bd6f271-767b-4293-aa18-ba28fe5a7fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.48.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.28.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vkush\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c176453b-c45c-47c2-a05b-7e3766d272df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meditation and yoga can improve mental health</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fruits, whole grains and vegetables helps control blood pressure</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These are the latest fashion trends for this week</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vibrant color jeans for male are becoming a trend</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The concert starts at 7 PM tonight</td>\n",
       "      <td>Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Navaratri dandiya program at Expo center in Mumbai this october</td>\n",
       "      <td>Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Exciting vacation destinations for your next trip</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maldives and Srilanka are gaining popularity in terms of low budget vacation places</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  text  \\\n",
       "0                                        Meditation and yoga can improve mental health   \n",
       "1                     Fruits, whole grains and vegetables helps control blood pressure   \n",
       "2                                    These are the latest fashion trends for this week   \n",
       "3                                    Vibrant color jeans for male are becoming a trend   \n",
       "4                                                   The concert starts at 7 PM tonight   \n",
       "5                      Navaratri dandiya program at Expo center in Mumbai this october   \n",
       "6                                    Exciting vacation destinations for your next trip   \n",
       "7  Maldives and Srilanka are gaining popularity in terms of low budget vacation places   \n",
       "\n",
       "  category  \n",
       "0   Health  \n",
       "1   Health  \n",
       "2  Fashion  \n",
       "3  Fashion  \n",
       "4    Event  \n",
       "5    Event  \n",
       "6   Travel  \n",
       "7   Travel  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\vkush\\\\OneDrive\\\\Desktop\\\\research equity tool\\\\sample_text.csv\")\n",
    "df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "afc16222-5948-45db-8c8c-da9c19e0ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 768)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "encoder =SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "vectors=encoder.encode(df.text)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "781cad4b-8efa-4f21-9403-c9b42aecc096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=vectors.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "59e30cb5-90a2-4b70-9512-1540c1f1d0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x000002510CAC2040> >"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "index=faiss.IndexFlatL2(dim)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a29f5cae-17c7-4b3a-8425-f00d53416732",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "14091c1c-620d-40f3-955a-27fa9d9ca183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query=\"I want to buy a polo t-shirt\"\n",
    "vec=encoder.encode(search_query)\n",
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ac9296ae-53b8-4726-b81f-50796efe7f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "svec=np.array(vec).reshape(1,-1)\n",
    "svec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4a761a64-069d-4401-81f8-f9bc17480ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.3844836, 1.4039096]], dtype=float32), array([[3, 2]], dtype=int64))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(svec, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b3115-a2e0-407a-954f-54835e52a306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
